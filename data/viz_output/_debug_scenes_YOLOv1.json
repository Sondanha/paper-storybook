[
  {
    "scene_id": 1,
    "title": "연구 동기와 문제 정의",
    "narration": "이 연구는 기존 객체 탐지 모델의 한계를 설명하며 시작합니다. 현재 객체 탐지 시스템들은 분류기를 재활용하여 탐지를 수행합니다. 이러한 접근법은 복잡한 파이프라인으로 인해 느리고 최적화하기 어려운 문제가 있습니다.",
    "raw_text": "Current detection systems repurpose classifiers to perform detection. To detect an object, these systems take a classifier for that object and evaluate it at various locations and scales in a test image. Systems like deformable parts models (DPM) use a sliding window approach where the classifier is run at evenly spaced locations over the entire image [CITATION]."
  },
  {
    "scene_id": 2,
    "title": "제안된 방법론",
    "narration": "연구진은 객체 탐지를 회귀 문제로 재정의하여, 한 번의 신경망 평가로 경계 상자 좌표와 클래스 확률을 직접 예측하는 YOLO 모델을 제안합니다. 이를 통해 전체 탐지 파이프라인을 end-to-end로 최적화할 수 있습니다.",
    "raw_text": "We reframe object detection as a single regression problem, straight from image pixels to bounding box coordinates and class probabilities. Using a single neural network, YOLO (You Only Look Once) predicts bounding boxes and class probabilities directly from full images in one evaluation."
  },
  {
    "scene_id": 3,
    "title": "YOLO 모델의 장점",
    "narration": "YOLO 모델은 기존 방식에 비해 매우 빠르며, 실시간으로 동작할 수 있습니다. 또한 YOLO는 일반적인 객체 표현을 학습하여 자연 이미지 외에도 다른 도메인, 예를 들어 미술 작품에서도 뛰어난 성능을 보입니다.",
    "raw_text": "Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors. Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork."
  },
  {
    "scene_id": 4,
    "title": "YOLO의 작동 원리",
    "narration": "YOLO는 입력 이미지 전체를 한 번에 처리하여 경계 상자와 클래스 확률을 직접 예측합니다. 이는 기존 방식과 달리 객체 탐지를 회귀 문제로 바라보는 접근법입니다.",
    "raw_text": "We present YOLO, a new approach to object detection. Prior work on object detection repurposes classifiers to perform detection. Instead, we frame object detection as a regression problem to spatially separated bounding boxes and associated class probabilities. A single neural network predicts bounding boxes and class probabilities directly from full images in one evaluation."
  },
  {
    "scene_id": 5,
    "title": "YOLO의 성능 평가",
    "narration": "YOLO는 기존 탐지 시스템에 비해 경계 상자 정확도가 다소 낮지만, 배경에 대한 잘못된 탐지 확률이 낮습니다. 또한 YOLO는 자연 이미지뿐만 아니라 다른 도메인, 예를 들어 미술 작품 등에서도 우수한 성능을 보입니다.",
    "raw_text": "Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background. Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork."
  },
  {
    "scene_id": 6,
    "title": "YOLO의 응용 분야",
    "narration": "YOLO와 같은 빠르고 정확한 객체 탐지 알고리즘은 자율주행 자동차, 보조 장치, 범용 로봇 시스템 등 다양한 응용 분야에 활용될 수 있습니다.",
    "raw_text": "Fast, accurate algorithms for object detection would allow computers to drive cars without specialized sensors, enable assistive devices to convey real-time scene information to human users, and unlock the potential for general purpose, responsive robotic systems."
  },
  {
    "scene_id": 7,
    "title": "YOLO의 주요 특징",
    "narration": "YOLO는 단일 신경망 구조로 이루어져 있어 end-to-end로 최적화할 수 있습니다. 이를 통해 기존 방식보다 훨씬 빠른 처리 속도를 달성할 수 있습니다.",
    "raw_text": "Our unified architecture is extremely fast. Our base YOLO model processes images in real-time at 45 frames per second. A smaller version of the network, Fast YOLO, processes an astounding 155 frames per second while still achieving double the mAP of other real-time detectors."
  },
  {
    "scene_id": 8,
    "title": "YOLO의 정확도",
    "narration": "YOLO는 기존 최첨단 탐지 시스템에 비해 경계 상자 정확도가 다소 낮지만, 배경에 대한 잘못된 탐지 확률이 낮아 전체적인 성능이 뛰어납니다.",
    "raw_text": "Compared to state-of-the-art detection systems, YOLO makes more localization errors but is less likely to predict false positives on background."
  },
  {
    "scene_id": 9,
    "title": "YOLO의 일반화 능력",
    "narration": "YOLO는 매우 일반적인 객체 표현을 학습하여, 자연 이미지뿐만 아니라 다른 도메인, 예를 들어 미술 작품에서도 기존 탐지 방법들을 능가하는 성능을 보입니다.",
    "raw_text": "Finally, YOLO learns very general representations of objects. It outperforms other detection methods, including DPM and R-CNN, when generalizing from natural images to other domains like artwork."
  },
  {
    "scene_id": 10,
    "title": "연구 결과 요약",
    "narration": "이 연구에서는 기존 객체 탐지 방식의 한계를 극복하기 위해 YOLO라는 새로운 접근법을 제안했습니다. YOLO는 매우 빠르고 일반화 능력이 뛰어나며, 기존 최첨단 탐지 시스템을 능가하는 성능을 보입니다.",
    "raw_text": "We present YOLO, a new approach to object detection. Our unified architecture is extremely fast. YOLO learns very general representations of objects and outperforms other detection methods when generalizing to different domains."
  }
]