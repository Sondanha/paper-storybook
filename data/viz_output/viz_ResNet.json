[
  {
    "scene_id": 1,
    "title": "연구 동기와 문제 정의",
    "narration": "이 논문은 더 깊은 신경망 모델이 학습하기 어려운 문제에 대해 다룹니다. 이를 해결하기 위해 잔차 학습이라는 새로운 프레임워크를 제안합니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Deeper Neural Network Challenges",
        "viz_prompt": "digraph G { rankdir=LR; DeepNet -> TrainingDifficulty; TrainingDifficulty -> ResidualLearning; }"
      },
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Residual Learning Framework",
        "viz_prompt": "digraph G { rankdir=LR; Input -> DeepNet; DeepNet -> Output; DeepNet -> Residual; Residual -> Output; }"
      }
    ]
  },
  {
    "scene_id": 2,
    "title": "잔차 학습 프레임워크 소개",
    "narration": "잔차 학습 프레임워크는 층마다 입력 대비 차이(잔차)를 학습하도록 합니다. 이를 통해 매우 깊은 신경망도 효과적으로 학습할 수 있습니다.",
    "error": "JSON parse failed",
    "raw": "{\n  \"scene_id\": 2,\n  \"title\": \"잔차 학습 프레임워크 소개\",\n  \"narration\": \"잔차 학습 프레임워크는 층마다 입력 대비 차이(잔차)를 학습하도록 합니다. 이를 통해 매우 깊은 신경망도 효과적으로 학습할 수 있습니다.\",\n  \"visualizations\": [\n    {\n      \"viz_type\": \"diagram\",\n      \"tool\": \"graphviz\",\n      \"viz_label\": \"Residual Learning\",\n      \"viz_prompt\": \"digraph G { rankdir=LR; Input -> Layer1 -> Add -> Output; Layer1 [label=\"Layer\"]; Add [label=\"+\"]; }\"\n    }\n  ]\n}"
  },
  {
    "scene_id": 3,
    "title": "실험 및 성능 평가",
    "narration": "ImageNet 데이터셋에서 152층 깊이의 잔차 신경망을 평가한 결과, VGG 모델보다 복잡도가 낮으면서도 뛰어난 성능을 보였습니다. 또한 앙상블 모델로 ImageNet 테스트 셋에서 오류율 3.57%를 달성하여 ILSVRC 2015 이미지 분류 과제 1위를 차지했습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Residual Net vs VGG",
        "viz_prompt": "digraph G { rankdir=LR; ResidualNet -> HighPerf; VGG -> HighCompl; HighPerf -> ImageNet; HighCompl -> ImageNet; }"
      },
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Ensemble Model",
        "viz_prompt": "digraph G { rankdir=LR; ResidualNets -> Ensemble -> ImageNet_Test; Ensemble -> ILSVRC2015_1st; }"
      }
    ]
  },
  {
    "scene_id": 4,
    "title": "CIFAR-10 실험 결과",
    "narration": "CIFAR-10 데이터셋에서도 100층, 1000층 깊이의 잔차 신경망을 실험했습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "CIFAR-10 Results",
        "viz_prompt": "digraph G { rankdir=LR; Input -> ResNet100 -> Output; Input -> ResNet1000 -> Output; }"
      }
    ]
  },
  {
    "scene_id": 5,
    "title": "시각 인식 태스크 성능 향상",
    "narration": "깊은 표현력을 가진 잔차 신경망을 활용하여 COCO 객체 탐지 데이터셋에서 28% 향상된 성능을 달성했습니다. 또한 ILSVRC와 COCO 2015 대회에서 이미지 분류, 객체 탐지, 영역 분할 등 다양한 과제에서 1위를 차지했습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Residual Network",
        "viz_prompt": "digraph G { rankdir=LR; Input -> ResidualBlock -> Output; }"
      },
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Benchmarks",
        "viz_prompt": "digraph G { rankdir=LR; COCO_Detection -> 28Percent_Improvement; ILSVRC_COCO2015 -> 1st_Place [label=\"Image Classification\nObject Detection\nSegmentation\"] }"
      }
    ]
  },
  {
    "scene_id": 6,
    "title": "신경망 깊이의 중요성",
    "narration": "많은 시각 인식 태스크에서 깊은 신경망의 중요성이 입증되었습니다. 이에 따라 과연 더 깊은 신경망을 학습하는 것이 쉬운지에 대한 질문이 제기됩니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Depth of Representations",
        "viz_prompt": "digraph G { rankdir=LR; Input -> ShallowModel; Input -> DeepModel; ShallowModel -> Output; DeepModel -> Output; DeepModel -> \"Better Performance\"; }"
      },
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Learning Deeper Networks",
        "viz_prompt": "digraph G { rankdir=LR; \"Shallow Network\" -> \"Deeper Network\" [label=\"More Challenging\"] }"
      }
    ]
  },
  {
    "scene_id": 7,
    "title": "더 깊은 신경망 학습의 장애물",
    "narration": "깊은 신경망 학습의 장애물로 알려진 것이 바닥/폭발 기울기 문제입니다. 그러나 이는 정규화된 초기화와 중간 정규화 레이어 도입으로 어느 정도 해결되었습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Vanishing/Exploding Gradients",
        "viz_prompt": "digraph G { rankdir=LR; Input -> DeepNet -> Output; DeepNet -> VanishingGradients [label=\"Vanishing\nGradients\"]; DeepNet -> ExplodingGradients [label=\"Exploding\nGradients\"]; }"
      },
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Solutions to Vanishing/Exploding Gradients",
        "viz_prompt": "digraph G { rankdir=LR; Input -> DeepNet -> Output; DeepNet -> NormalizedInit [label=\"Normalized\nInitialization\"]; DeepNet -> NormalizationLayers [label=\"Normalization\nLayers\"]; }"
      }
    ]
  },
  {
    "scene_id": 8,
    "title": "깊은 신경망의 학습 어려움",
    "narration": "그럼에도 불구하고 여전히 훨씬 더 깊은 신경망을 효과적으로 학습하는 것은 쉽지 않습니다. 이를 해결하기 위한 새로운 접근이 필요합니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Challenges of Deep Networks",
        "viz_prompt": "digraph G { rankdir=LR; DeepNetwork -> [\"Training Difficulty\", \"Vanishing/Exploding Gradients\", \"Optimization Challenges\"]; }"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "Deep vs Shallow Networks",
        "viz_prompt": "A visual comparison of deep and shallow neural networks, highlighting the challenges of training deeper models."
      }
    ]
  },
  {
    "scene_id": 9,
    "title": "실험 설계 및 결과 요약",
    "narration": "논문에서는 깊이 152층의 잔차 신경망 모델을 ImageNet 데이터셋에 대해 평가했습니다. 그 결과 VGG 모델보다 복잡도가 낮으면서도 우수한 성능을 보였고, 앙상블 모델로 ILSVRC 2015 이미지 분류 1위를 달성했습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Residual Net vs VGG",
        "viz_prompt": "digraph G { rankdir=LR; VGG -> HighComplexity; ResidualNet -> LowComplexity; HighComplexity -> HighPerformance; LowComplexity -> HighPerformance; }"
      },
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "ILSVRC 2015 Result",
        "viz_prompt": "digraph G { rankdir=LR; ResidualNetEnsemble -> FirstPlace; }"
      }
    ]
  },
  {
    "scene_id": 10,
    "title": "결론 및 향후 연구 방향",
    "narration": "이 연구는 깊은 잔차 신경망 모델을 통해 다양한 시각 인식 태스크에서 뛰어난 성능을 달성했습니다. 향후 이러한 깊은 표현력을 가진 모델을 더욱 발전시켜 복잡한 비전 문제 해결에 활용할 계획입니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Deep Residual Nets for Visual Tasks",
        "viz_prompt": "digraph G { rankdir=LR; InputImage -> DeepResidualNets -> ImageNetDetection; DeepResidualNets -> ImageNetLocalization; DeepResidualNets -> COCODetection; DeepResidualNets -> COCOSegmentation; }"
      }
    ]
  }
]