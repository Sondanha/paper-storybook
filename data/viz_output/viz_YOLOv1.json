[
  {
    "scene_id": 1,
    "title": "연구 동기와 문제 정의",
    "narration": "이 연구는 객체 탐지 문제를 새로운 접근법으로 해결하고자 합니다. 기존 방식은 분류기를 물체 탐지에 재활용하는 방식이었지만, 이는 복잡하고 최적화가 어려운 파이프라인을 가지고 있었습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Existing Object Detection Pipeline",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  Classifier -> Detection;\\n  Detection -> Output;\\n  label=\"Existing Object Detection Pipeline\";\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "Simplified Illustration",
        "viz_prompt": "This illustration shows a simplified view of the existing object detection pipeline, where a classifier is repurposed to perform detection by evaluating it at various locations and scales in the test image. This pipeline is complex and difficult to optimize."
      }
    ]
  },
  {
    "scene_id": 2,
    "title": "제안된 방법론",
    "narration": "저자들은 객체 탐지 문제를 단일 회귀 문제로 재정의합니다. 이미지 픽셀을 입력으로 받아 바운딩 박스 좌표와 클래스 확률을 직접 예측하는 통합 아키텍처를 제안합니다. 이를 통해 end-to-end 최적화가 가능해집니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Proposed Architecture",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  input [label=\"Image\\nPixels\"];\n  model [label=\"Integrated\\nArchitecture\"];\n  output [label=\"Bounding Boxes\\n& Class Probabilities\"];\n  input -> model -> output;\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "End-to-End Optimization",
        "viz_prompt": "A diagram showing the end-to-end optimization process of the proposed architecture, where the model directly predicts bounding box coordinates and class probabilities from the input image pixels."
      }
    ]
  },
  {
    "scene_id": 3,
    "title": "YOLO 모델 구조",
    "narration": "제안하는 YOLO (You Only Look Once) 모델은 단일 신경망으로 구성되어 있습니다. 이미지 전체를 한번에 입력받아 실시간으로 객체 탐지를 수행할 수 있습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "YOLO Model Architecture",
        "viz_prompt": "digraph G {\\n  rankdir=TB;\\n  node [shape=box];\\n  input [label=\"Image Input\"];\n  backbone [label=\"Backbone\\n(CNN)\"];\n  head [label=\"Detection\\nHead\"];\n  output [label=\"Object Detections\"];\n\n  input -> backbone -> head -> output;\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "Real-time Object Detection",
        "viz_prompt": "The YOLO model is capable of processing entire images in real-time, detecting objects and their locations simultaneously."
      }
    ]
  },
  {
    "scene_id": 4,
    "title": "YOLO 모델 성능",
    "narration": "YOLO 모델은 기존 객체 탐지 방식보다 위치 오차는 크지만, 배경에 대한 오탐지 오류는 적습니다. 또한 자연 이미지에서 학습한 일반적인 표현을 다른 도메인의 이미지에 대해서도 잘 적용할 수 있습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Comparison of YOLO and State-of-the-Art Detection",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  subgraph cluster_yolo { label=\"YOLO\"; shape=box; Localization -> FalsePositives; }\n  subgraph cluster_sota { label=\"State-of-the-Art\"; shape=box; SotaLocalization -> SotaFalsePositives; }\n  Localization -> SotaLocalization [label=\"Higher\"];\n  FalsePositives -> SotaFalsePositives [label=\"Lower\"];\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "YOLO's Generalization Ability",
        "viz_prompt": "YOLO's learned representations can be effectively applied to different domains, like natural images and artwork, showing its strong generalization capabilities."
      }
    ]
  },
  {
    "scene_id": 5,
    "title": "연구의 목표와 기여",
    "narration": "이 연구의 최종 목표는 자율주행, 보조 기기, 로봇 시스템 등에 적용할 수 있는 빠르고 정확한 객체 탐지 알고리즘을 개발하는 것입니다. YOLO 모델은 기존 방식에 비해 실시간 성능이 매우 우수하며, end-to-end 최적화가 가능한 통합 아키텍처를 제안합니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Object Detection Applications",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  node [shape=box];\\n  \\n  \"Autonomous Driving\" -> \"Object Detection\";\n  \"Assistive Devices\" -> \"Object Detection\";\n  \"Robotic Systems\" -> \"Object Detection\";\n  \"Object Detection\" -> \"Fast, Accurate Algorithms\";\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "YOLO Model",
        "viz_prompt": "The YOLO model is an integrated architecture that provides very high real-time performance compared to existing methods, and enables end-to-end optimization."
      }
    ]
  },
  {
    "scene_id": 6,
    "title": "YOLO 모델 성능 평가",
    "narration": "YOLO 모델은 초당 45프레임의 빠른 속도로 객체 탐지를 수행할 수 있습니다. 더 작은 버전인 Fast YOLO는 초당 155프레임의 실시간 처리 속도를 달성하면서도 다른 실시간 탐지기보다 두 배 이상의 성능을 보입니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "YOLO Model Performance",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  node [shape=box];\\n  \\n  \"YOLO Model\" [label=\"YOLO Model\\n45 FPS\"];\n  \"Fast YOLO\" [label=\"Fast YOLO\\n155 FPS\"];\n  \n  \"YOLO Model\" -> \"Other Real-Time Detectors\" [label=\"2x mAP\"];\n  \"Fast YOLO\" -> \"Other Real-Time Detectors\" [label=\"2x mAP\"];\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "YOLO Comparison",
        "viz_prompt": "A comparison of the YOLO and Fast YOLO models, highlighting their real-time processing speeds and performance advantages over other detectors."
      }
    ]
  },
  {
    "scene_id": 7,
    "title": "YOLO 모델의 특징",
    "narration": "YOLO 모델은 단일 신경망으로 구성되어 있어 end-to-end로 최적화할 수 있습니다. 또한 기존 방식에 비해 위치 오차는 크지만 배경에 대한 오탐지 오류는 적습니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "YOLO Model Architecture",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  Input -> YOLOModel -> Output;\\n  YOLOModel [shape=box];\\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "Comparison of YOLO and Traditional Detectors",
        "viz_prompt": "YOLO model has a single neural network architecture that can be optimized end-to-end, unlike traditional detectors. YOLO has higher localization error but lower background false positive rate compared to state-of-the-art detection systems."
      }
    ]
  },
  {
    "scene_id": 8,
    "title": "YOLO 모델의 일반화 성능",
    "narration": "YOLO 모델은 자연 이미지에서 학습한 일반적인 객체 표현을 다른 도메인의 이미지에 대해서도 잘 적용할 수 있습니다. 이는 YOLO가 기존 탐지기들보다 뛰어난 일반화 성능을 보인다는 것을 의미합니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "YOLO 일반화 성능",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  \"Natural Images\" -> \"YOLO Model\" -> \"Other Domains\";\n  \"YOLO Model\" -> \"Improved Generalization\";\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "YOLO 모델의 일반화 능력",
        "viz_prompt": "YOLO 모델은 자연 이미지에서 학습한 일반적인 객체 표현을 다른 도메인의 이미지에 대해서도 잘 적용할 수 있습니다. 이는 기존 탐지기들보다 YOLO가 뛰어난 일반화 성능을 보인다는 것을 의미합니다."
      }
    ]
  },
  {
    "scene_id": 9,
    "title": "논문 요약",
    "narration": "이 논문에서는 단일 신경망 기반의 YOLO 객체 탐지 모델을 제안합니다. YOLO 모델은 기존 복잡한 파이프라인 방식보다 빠르고 end-to-end로 최적화할 수 있습니다. 또한 다른 탐지기에 비해 일반화 성능이 뛰어납니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "YOLO vs. Pipeline",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  subgraph cluster_pipeline {\\n    label=\"Traditional Pipeline\";\n    Input -> FeatureExtract -> Classify -> BoundingBox;\n  }\n  subgraph cluster_yolo {\n    label=\"YOLO\";\n    \"Single NN\" -> \"Bounding Box\" -> \"Class Prob\";\n  }\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "YOLO Model Overview",
        "viz_prompt": "A neural network that takes a full image as input and predicts bounding boxes and class probabilities directly. This end-to-end approach is faster and more generalized compared to traditional object detection pipelines."
      }
    ]
  },
  {
    "scene_id": 10,
    "title": "연구의 기대 효과",
    "narration": "이 연구에서 제안한 YOLO 모델은 자율주행, 보조 기기, 로봇 시스템 등 다양한 분야에 활용될 수 있을 것으로 기대됩니다. 빠르고 정확한 객체 탐지 기능을 통해 이러한 응용 분야의 발전에 기여할 것으로 보입니다.",
    "visualizations": [
      {
        "viz_type": "diagram",
        "tool": "graphviz",
        "viz_label": "Application Domains",
        "viz_prompt": "digraph G {\\n  rankdir=LR;\\n  node [shape=box];\\n  Autonomous_Driving -> \"Assistive\nDevices\";\n  Autonomous_Driving -> Robotics;\n  \"Assistive\nDevices\" -> Robotics;\n}",
        "layout": "dot"
      },
      {
        "viz_type": "illustration",
        "tool": "stability",
        "viz_label": "YOLO Model Capabilities",
        "viz_prompt": "The YOLO model proposed in this research is expected to enable fast and accurate object detection, which can contribute to the advancement of various application domains such as autonomous driving, assistive devices, and robotic systems."
      }
    ]
  }
]